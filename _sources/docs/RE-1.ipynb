{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alternative-artwork"
   },
   "source": [
    "# RE task 기초 베이스라인 1\n",
    "\n",
    "- Task : KLUE-RE\n",
    "- 담당자: [김보석](https://github.com/BOSOEK) 님\n",
    "- 최종수정일: 21-09-15\n",
    "- 본 자료는 가짜연구소 3기 KLUE 로 모델 평가하기 크루 활동으로 작성됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10907,
     "status": "ok",
     "timestamp": 1631506891711,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "alternate-solid",
    "outputId": "c0e8f542-7a39-4dec-e4b8-bbf1b33e5696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.16)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install sklearn\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "funny-monster"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn.metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "confident-advance"
   },
   "source": [
    "### 데이터 셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1631507007833,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "functional-devices",
    "outputId": "ce510b85-3e8d-4aec-d23f-57c7372ae01f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset klue (/root/.cache/huggingface/datasets/klue/re/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source'],\n",
       "        num_rows: 32470\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source'],\n",
       "        num_rows: 7765\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('klue', 're')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-wTFwLGZhhH"
   },
   "source": [
    "### 데이터 살짝 맛보기\n",
    "input은 sentence, output은 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1631509973998,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "aging-lingerie",
    "outputId": "f11e12f6-2ccd-4a21-c47c-a9069d9fd792"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'klue-re-v1_train_00000',\n",
       " 'label': 0,\n",
       " 'object_entity': {'end_idx': 18,\n",
       "  'start_idx': 13,\n",
       "  'type': 'PER',\n",
       "  'word': '조지 해리슨'},\n",
       " 'sentence': '〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.',\n",
       " 'source': 'wikipedia',\n",
       " 'subject_entity': {'end_idx': 26,\n",
       "  'start_idx': 24,\n",
       "  'type': 'ORG',\n",
       "  'word': '비틀즈'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 구성\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "starting-boating"
   },
   "source": [
    "# 토큰 추가\n",
    "__sentence__에 관계 단어 두개를 표시하기 위해 특별 토큰을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1631511108713,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "Epk_WdZuo4Gc",
    "outputId": "bbca6522-e6d4-42f9-9fb9-631f243bb66f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_idx': 26, 'start_idx': 24, 'type': 'ORG', 'word': '비틀즈'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['subject_entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "directed-direction"
   },
   "outputs": [],
   "source": [
    "def add_Token(dataset):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for data in dataset:\n",
    "        sentence = data['sentence']\n",
    "\n",
    "        object_start =  int(data['object_entity']['start_idx'])\n",
    "        object_end =  int(data['object_entity']['end_idx'])\n",
    "        subject_start =  int(data['subject_entity']['start_idx'])\n",
    "        subject_end =  int(data['subject_entity']['end_idx'])\n",
    "\n",
    "        if object_start < subject_start:\n",
    "            new_sentence = sentence[:object_start] + '<o>' + sentence[object_start:object_end+1] + '</o>' + sentence[object_end+1:subject_start] + '<s>' + sentence[subject_start:subject_end+1] + '</s>' + sentence[subject_end+1:]\n",
    "        else:\n",
    "            new_sentence = sentence[:subject_start] + '<s>' + sentence[subject_start:subject_end+1] + '</s>' + sentence[subject_end+1:object_start] + '<o>' + sentence[object_start:object_end+1] + '</o>' + sentence[object_end+1:]\n",
    "\n",
    "        # 본문 저장\n",
    "        sentences.append(new_sentence)\n",
    "\n",
    "        # 레이블 저장\n",
    "        labels.append(data['label'])\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "valuable-nightmare"
   },
   "outputs": [],
   "source": [
    "# train, validation데이터셋에서 sentence와 label만 저장.\n",
    "train_sentences, train_labels = add_Token(dataset['train'])\n",
    "val_sentences, val_labels = add_Token(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1631511435932,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "intellectual-conflict",
    "outputId": "b8a909bb-f0d6-4811-9c0e-4ed35096b15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "〈Something〉는 <o>조지 해리슨</o>이 쓰고 <s>비틀즈</s>가 1969년 앨범 《Abbey Road》에 담은 노래다. \n",
      "\n",
      "호남이 기반인 바른미래당·<o>대안신당</o>·<s>민주평화당</s>이 우여곡절 끝에 합당해 민생당(가칭)으로 재탄생한다. \n",
      "\n",
      "K리그2에서 성적 1위를 달리고 있는 <s>광주FC</s>는 지난 26일 <o>한국프로축구연맹</o>으로부터 관중 유치 성과와 마케팅 성과를 인정받아 ‘풀 스타디움상’과 ‘플러스 스타디움상’을 수상했다. \n",
      "\n",
      "균일가 생활용품점 (주)<s>아성다이소</s>(대표 <o>박정부</o>)는 코로나19 바이러스로 어려움을 겪고 있는 대구광역시에 행복박스를 전달했다고 10일 밝혔다. \n",
      "\n",
      "<o>1967</o>년 프로 야구 드래프트 1순위로 <s>요미우리 자이언츠</s>에게 입단하면서 등번호는 8번으로 배정되었다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토큰 확인하기.\n",
    "for sentence in train_sentences[:5]:\n",
    "    print(sentence, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "labeled-division"
   },
   "source": [
    "# klue/bert-base 토크나이저 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "placed-bulgarian"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alien-crack"
   },
   "source": [
    "### token 추가하기\n",
    "__sentence__에 추가한 subject, object 토큰들을 토크나이저에 등록해야 해당 token들이 token화 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prime-weekend"
   },
   "outputs": [],
   "source": [
    "new_enrollment_tokens = {'additional_special_tokens': ['<o>', '</o>', '<s>', '</s>']}\n",
    "enrollment_tokens = tokenizer.add_special_tokens(new_enrollment_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "assigned-photograph"
   },
   "source": [
    "학습에 필요한 값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blessed-albuquerque"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_labels = 30\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "modified-grammar"
   },
   "source": [
    "### 학습 데이터셋과 데이터로더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "illegal-cincinnati"
   },
   "outputs": [],
   "source": [
    "class makeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, sentences, labels, max_length=128):\n",
    "        self.encodings = tokenizer(sentences,\n",
    "                                   max_length=max_length,\n",
    "                                   padding='max_length',\n",
    "                                   truncation=True)\n",
    "        self.labels = labels\n",
    "\n",
    "train_dataset = KlueReDataset(tokenizer, train_sentences, train_labels)\n",
    "val_dataset = KlueReDataset(tokenizer, val_sentences, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuclear-thomas"
   },
   "source": [
    "# klue/bert-base 모델을 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2163,
     "status": "ok",
     "timestamp": 1631512353622,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "recreational-monitoring",
    "outputId": "7a94e330-a951-4eb1-fb90-90a7b25a8328"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "subtle-attachment"
   },
   "source": [
    "### Embedding resize\n",
    "\n",
    "지금의 BERT Embedding Layer에는 추가했던 subject, object의 4개 토큰 정보가 반영되지 않았기 때문에  __index error__가 발생! \n",
    "\n",
    "때문에 Embedding Layer의 input이 32000에서 32004로 resize해준다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1631512538937,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "quality-management",
    "outputId": "49342885-1be1-4a5f-d84b-47db7b95ab50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32004, 768)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "applied-ethnic"
   },
   "source": [
    "학습 도중 Loss, Accuracy 계산 및 저장을 간단하게 하기 위해 AverageMeter를 클래스를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "general-lawrence"
   },
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "federal-attack"
   },
   "source": [
    "### model fine-tuning\n",
    "BERT-base 모델을 fine-tuning합니다.\n",
    "\n",
    "구글 코랩에서 epoch 당 25~30분 정도가 소요됍니다.(ㄷㄷ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1749997,
     "status": "ok",
     "timestamp": 1631517760388,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "assisted-doctor",
    "outputId": "f88cb18a-3547-43af-d606-ba623748130c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Epoch 1 / 1 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4059/4059 [27:03<00:00,  2.50it/s]\n",
      "100%|██████████| 971/971 [02:04<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5199, train_acc: 0.8220, val_loss: 0.7974, val_acc: 0.7378\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, criterion, optimizer, train=True):\n",
    "    loss_save = AverageMeter()\n",
    "    acc_save = AverageMeter()\n",
    "    \n",
    "    # progress bar 생성\n",
    "    for _, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'token_type_ids': batch['token_type_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "        }\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs['logits']\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = ((preds == labels).sum().item() / labels.shape[0])\n",
    "        \n",
    "        loss_save.update(loss, labels.shape[0])\n",
    "        acc_save.update(acc, labels.shape[0])\n",
    "        \n",
    "    results = {\n",
    "        'loss': loss_save.avg,\n",
    "        'acc': acc_save.avg,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "        \n",
    "\n",
    "epochs = 1\n",
    "\n",
    "# loss function, optimizer 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'< Epoch {epoch+1} / {epochs} >')\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    train_results = train_model(train_loader, model, criterion, optimizer)\n",
    "    train_loss, train_acc = train_results['loss'], train_results['acc']\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_results = train_model(val_loader, model, criterion, optimizer, False)\n",
    "        val_loss, val_acc = val_results['loss'], val_results['acc']\n",
    "    \n",
    "    \n",
    "    print(f'train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}')\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "relevant-freight"
   },
   "source": [
    "### 결과 확인\n",
    "\n",
    "실제 20개의 head 데이터로 확인 결과 3개 제외한 답이 정답이였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1631520576939,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "PnA0hecfMRfA",
    "outputId": "8067d7b9-0b22-40b9-cb2a-0d815fdd17dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([10], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 18, 추측 값 : tensor([18], device='cuda:0')\n",
      "label : 17, 추측 값 : tensor([17], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 10, 추측 값 : tensor([10], device='cuda:0')\n",
      "label : 10, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 6, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 3, 추측 값 : tensor([3], device='cuda:0')\n",
      "label : 8, 추측 값 : tensor([8], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 29, 추측 값 : tensor([29], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 0, 추측 값 : tensor([0], device='cuda:0')\n",
      "label : 18, 추측 값 : tensor([18], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    val = encoding = tokenizer(val_sentences[i], max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    val_input = {\n",
    "    'input_ids': val['input_ids'].to(device),\n",
    "    'token_type_ids': val['token_type_ids'].to(device),\n",
    "    'attention_mask': val['attention_mask'].to(device),\n",
    "    }\n",
    "    model.eval()\n",
    "    output = model(**val_input)\n",
    "    label = torch.argmax(output['logits'], dim=1)\n",
    "    print('label : ' + str(val_labels[i]) + ', 추측 값 : ' + str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spread-wedding"
   },
   "source": [
    "### 모델 평가하기\n",
    "F1 score의 성능만 일단 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "identical-steps"
   },
   "outputs": [],
   "source": [
    "def calc_f1_score(preds, labels):\n",
    "    preds_relation = []\n",
    "    labels_relation = []\n",
    "    \n",
    "    for pred, label in zip(preds, labels):\n",
    "        preds_relation.append(pred)\n",
    "        labels_relation.append(label)\n",
    "\n",
    "    f1_score = sklearn.metrics.f1_score(labels_relation, preds_relation, average='micro', zero_division=1)\n",
    "    \n",
    "    return f1_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120131,
     "status": "ok",
     "timestamp": 1631520896036,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "divided-workstation",
    "outputId": "94249873-fa66-4490-94b0-5cef90748015"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 971/971 [02:00<00:00,  8.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    label_all = []\n",
    "    pred_all = []\n",
    "    for batch in tqdm(val_loader):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'token_type_ids': batch['token_type_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "        }\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs['logits']\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        label_all.extend(labels.detach().cpu().numpy().tolist())\n",
    "        pred_all.extend(preds.detach().cpu().numpy().tolist())\n",
    "    \n",
    "    f1_score = calc_f1_score(label_all, pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "greenhouse-residence"
   },
   "source": [
    "F1 score : 73.7797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1631520933260,
     "user": {
      "displayName": "김보석",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08969752424908754753"
     },
     "user_tz": -540
    },
    "id": "civilian-costa",
    "outputId": "cd9040fe-3550-4457-8b75-062a99a857b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.77978106889891"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Relation_extraction-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
